{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "         index  Project_ID    Year  N_of_SCI  N_of_Paper  N_Patent_App  \\\n0            0  1055000474  2013.0       0.0         0.0           0.0   \n1            1  1055000475  2013.0       0.0         0.0           0.0   \n2            2  1055000476  2014.0       0.0         0.0           0.0   \n3            3  1055000477  2014.0       0.0         0.0           0.0   \n4            4  1055000478  2014.0       0.0         0.0           0.0   \n...        ...         ...     ...       ...         ...           ...   \n192874  192874  9991006121  2016.0       0.0         0.0           2.0   \n192875  192875  9991006122  2016.0       0.0         0.0           0.0   \n192876  192876  9991006124  2016.0       0.0         0.0           0.0   \n192877  192877  9991006125  2016.0       0.0         0.0           2.0   \n192878  192878  9991006126  2016.0       0.0         0.0           0.0   \n\n        N_Patent_Reg  N_of_Korean_Patent  N_of_Inter_Patent  N_of_Patent  ...  \\\n0                0.0                 0.0                0.0          0.0  ...   \n1                0.0                 0.0                0.0          0.0  ...   \n2                0.0                 0.0                0.0          0.0  ...   \n3                0.0                 0.0                0.0          0.0  ...   \n4                0.0                 0.0                0.0          0.0  ...   \n...              ...                 ...                ...          ...  ...   \n192874           1.0                 3.0                0.0          3.0  ...   \n192875           0.0                 0.0                0.0          0.0  ...   \n192876           0.0                 0.0                0.0          0.0  ...   \n192877           2.0                 4.0                0.0          4.0  ...   \n192878           0.0                 0.0                0.0          0.0  ...   \n\n        Cowork_Abroad  Cowork_etc  Log_RnD_Fund Log_Duration  Comm_Success  \\\n0                   N           N     21.365120     5.897157           0.0   \n1                   N           N     19.568083     5.897157           0.0   \n2                   N           N     21.365120     5.897157           0.0   \n3                   N           N     19.673444     5.808145           0.0   \n4                   N           N     17.504390     4.804029           0.0   \n...               ...         ...           ...          ...           ...   \n192874              N           N     20.723266     6.302621           0.0   \n192875              N           Y     21.920324     6.302621           0.0   \n192876              N           N     20.482467     6.998511           0.0   \n192877              N           N     20.430236     6.998511           1.0   \n192878              N           N     20.584004     6.998511           0.0   \n\n       Comm_Success_1  Comm_Success_2 Comm_Success_Code1_4  \\\n0                 0.0             0.0                  0.0   \n1                 0.0             0.0                  0.0   \n2                 0.0             0.0                  0.0   \n3                 0.0             0.0                  0.0   \n4                 0.0             0.0                  0.0   \n...               ...             ...                  ...   \n192874            0.0             0.0                  0.0   \n192875            0.0             0.0                  0.0   \n192876            0.0             0.0                  0.0   \n192877            1.0             0.0                  0.0   \n192878            0.0             0.0                  0.0   \n\n        Comm_Success_Code2_5 Comm_Success_Code3_6  \n0                        0.0                  0.0  \n1                        0.0                  0.0  \n2                        0.0                  0.0  \n3                        0.0                  0.0  \n4                        0.0                  0.0  \n...                      ...                  ...  \n192874                   0.0                  0.0  \n192875                   0.0                  0.0  \n192876                   0.0                  0.0  \n192877                   1.0                  0.0  \n192878                   0.0                  0.0  \n\n[192879 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Project_ID</th>\n      <th>Year</th>\n      <th>N_of_SCI</th>\n      <th>N_of_Paper</th>\n      <th>N_Patent_App</th>\n      <th>N_Patent_Reg</th>\n      <th>N_of_Korean_Patent</th>\n      <th>N_of_Inter_Patent</th>\n      <th>N_of_Patent</th>\n      <th>...</th>\n      <th>Cowork_Abroad</th>\n      <th>Cowork_etc</th>\n      <th>Log_RnD_Fund</th>\n      <th>Log_Duration</th>\n      <th>Comm_Success</th>\n      <th>Comm_Success_1</th>\n      <th>Comm_Success_2</th>\n      <th>Comm_Success_Code1_4</th>\n      <th>Comm_Success_Code2_5</th>\n      <th>Comm_Success_Code3_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1055000474</td>\n      <td>2013.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1055000475</td>\n      <td>2013.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>19.568083</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1055000476</td>\n      <td>2014.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1055000477</td>\n      <td>2014.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>19.673444</td>\n      <td>5.808145</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1055000478</td>\n      <td>2014.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>17.504390</td>\n      <td>4.804029</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>192874</th>\n      <td>192874</td>\n      <td>9991006121</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>20.723266</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192875</th>\n      <td>192875</td>\n      <td>9991006122</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>21.920324</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192876</th>\n      <td>192876</td>\n      <td>9991006124</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>20.482467</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192877</th>\n      <td>192877</td>\n      <td>9991006125</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>20.430236</td>\n      <td>6.998511</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192878</th>\n      <td>192878</td>\n      <td>9991006126</td>\n      <td>2016.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>N</td>\n      <td>N</td>\n      <td>20.584004</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>192879 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/keumhyeonjun/Projects/kisti_renewal/dataset_final/Dataset_4_2016.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "NUMERIC_COLUMN = [\n",
    "    \"Log_RnD_Fund\",\n",
    "    \"Log_Duration\",\n",
    "    \"N_of_SCI\",\n",
    "    \"N_of_Paper\",\n",
    "    \"N_Patent_App\",\n",
    "    \"N_Patent_Reg\",\n",
    "    \"N_of_Korean_Patent\",\n",
    "    \"STP_Code_1_Weight\",\n",
    "    \"STP_Code_2_Weight\",\n",
    "    \"Application_Area_1_Weight\",\n",
    "    \"Application_Area_2_Weight\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLUMN = [\n",
    "    \"Year\",\n",
    "    \"Multi_Year\",\n",
    "    \"RnD_Org\",\n",
    "    \"STP_Code_11\",\n",
    "    \"STP_Code_21\",\n",
    "    \"Application_Area_1\",\n",
    "    \"Application_Area_2\",\n",
    "    \"Green_Tech\",\n",
    "    \"SixT_2\",\n",
    "    \"Econ_Social\",\n",
    "    \"National_Strategy_2\",\n",
    "    \"RnD_Stage\",\n",
    "    \"Cowork_Cor\",\n",
    "    \"Cowork_Uni\",\n",
    "    \"Cowork_Inst\",\n",
    "    \"Cowork_Abroad\",\n",
    "    \"Cowork_etc\",\n",
    "]\n",
    "\n",
    "LABEL_COLUMN = [\"Comm_Success\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 불필요한 컬럼 제거(데이터로 사용하지 않을 것들)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "ALL_COLUMN = df.columns.tolist()\n",
    "UNNESSARY_COLUMN=list(set(ALL_COLUMN)-set(NUMERIC_COLUMN)-set(CATEGORICAL_COLUMN)-set(LABEL_COLUMN))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "        Log_RnD_Fund  Log_Duration  N_of_SCI  N_of_Paper  N_Patent_App  \\\n0          21.365120      5.897157       0.0         0.0           0.0   \n1          19.568083      5.897157       0.0         0.0           0.0   \n2          21.365120      5.897157       0.0         0.0           0.0   \n3          19.673444      5.808145       0.0         0.0           0.0   \n4          17.504390      4.804029       0.0         0.0           0.0   \n...              ...           ...       ...         ...           ...   \n192874     20.723266      6.302621       0.0         0.0           2.0   \n192875     21.920324      6.302621       0.0         0.0           0.0   \n192876     20.482467      6.998511       0.0         0.0           0.0   \n192877     20.430236      6.998511       0.0         0.0           2.0   \n192878     20.584004      6.998511       0.0         0.0           0.0   \n\n        N_Patent_Reg  N_of_Korean_Patent  STP_Code_1_Weight  \\\n0                0.0                 0.0              100.0   \n1                0.0                 0.0              100.0   \n2                0.0                 0.0              100.0   \n3                0.0                 0.0              100.0   \n4                0.0                 0.0                0.0   \n...              ...                 ...                ...   \n192874           1.0                 3.0               50.0   \n192875           0.0                 0.0              100.0   \n192876           0.0                 0.0               80.0   \n192877           2.0                 4.0              100.0   \n192878           0.0                 0.0               50.0   \n\n        STP_Code_2_Weight  Application_Area_1_Weight  ...  SixT_2  \\\n0                     0.0                      100.0  ...   70000   \n1                     0.0                      100.0  ...   70000   \n2                     0.0                      100.0  ...   70000   \n3                     0.0                      100.0  ...   70000   \n4                     0.0                      100.0  ...   70000   \n...                   ...                        ...  ...     ...   \n192874               30.0                       50.0  ...   20200   \n192875                0.0                      100.0  ...   20200   \n192876               20.0                       60.0  ...   30200   \n192877                0.0                      100.0  ...   30200   \n192878               30.0                       50.0  ...   50100   \n\n        Econ_Social  National_Strategy_2  RnD_Stage Cowork_Cor Cowork_Uni  \\\n0                13                60000          4          N          N   \n1                13                60000          4          N          N   \n2                13                60000          4          N          N   \n3                13                60000          4          N          N   \n4                13                60000          4          N          N   \n...             ...                  ...        ...        ...        ...   \n192874           11                40100          2          N          N   \n192875            4                60000          3          N          N   \n192876            7                10500          3          Y          N   \n192877            7                10500          3          Y          N   \n192878            7                30200          4          Y          Y   \n\n       Cowork_Inst Cowork_Abroad  Cowork_etc  Comm_Success  \n0                N             N           N           0.0  \n1                N             N           N           0.0  \n2                N             N           N           0.0  \n3                N             N           N           0.0  \n4                N             N           N           0.0  \n...            ...           ...         ...           ...  \n192874           N             N           N           0.0  \n192875           N             N           Y           0.0  \n192876           Y             N           N           0.0  \n192877           Y             N           N           1.0  \n192878           Y             N           N           0.0  \n\n[192879 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Log_RnD_Fund</th>\n      <th>Log_Duration</th>\n      <th>N_of_SCI</th>\n      <th>N_of_Paper</th>\n      <th>N_Patent_App</th>\n      <th>N_Patent_Reg</th>\n      <th>N_of_Korean_Patent</th>\n      <th>STP_Code_1_Weight</th>\n      <th>STP_Code_2_Weight</th>\n      <th>Application_Area_1_Weight</th>\n      <th>...</th>\n      <th>SixT_2</th>\n      <th>Econ_Social</th>\n      <th>National_Strategy_2</th>\n      <th>RnD_Stage</th>\n      <th>Cowork_Cor</th>\n      <th>Cowork_Uni</th>\n      <th>Cowork_Inst</th>\n      <th>Cowork_Abroad</th>\n      <th>Cowork_etc</th>\n      <th>Comm_Success</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>70000</td>\n      <td>13</td>\n      <td>60000</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19.568083</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>70000</td>\n      <td>13</td>\n      <td>60000</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>70000</td>\n      <td>13</td>\n      <td>60000</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19.673444</td>\n      <td>5.808145</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>70000</td>\n      <td>13</td>\n      <td>60000</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.504390</td>\n      <td>4.804029</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>70000</td>\n      <td>13</td>\n      <td>60000</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>192874</th>\n      <td>20.723266</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>30.0</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>20200</td>\n      <td>11</td>\n      <td>40100</td>\n      <td>2</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192875</th>\n      <td>21.920324</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>20200</td>\n      <td>4</td>\n      <td>60000</td>\n      <td>3</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192876</th>\n      <td>20.482467</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>20.0</td>\n      <td>60.0</td>\n      <td>...</td>\n      <td>30200</td>\n      <td>7</td>\n      <td>10500</td>\n      <td>3</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192877</th>\n      <td>20.430236</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>30200</td>\n      <td>7</td>\n      <td>10500</td>\n      <td>3</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>192878</th>\n      <td>20.584004</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>30.0</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>50100</td>\n      <td>7</td>\n      <td>30200</td>\n      <td>4</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>192879 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[NUMERIC_COLUMN+CATEGORICAL_COLUMN+LABEL_COLUMN]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### [LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero >> 해결하기\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "        Log_RnD_Fund  Log_Duration  N_of_SCI  N_of_Paper  N_Patent_App  \\\n0          21.365120      5.897157       0.0         0.0           0.0   \n1          19.568083      5.897157       0.0         0.0           0.0   \n2          21.365120      5.897157       0.0         0.0           0.0   \n3          19.673444      5.808145       0.0         0.0           0.0   \n4          17.504390      4.804029       0.0         0.0           0.0   \n...              ...           ...       ...         ...           ...   \n192874     20.723266      6.302621       0.0         0.0           2.0   \n192875     21.920324      6.302621       0.0         0.0           0.0   \n192876     20.482467      6.998511       0.0         0.0           0.0   \n192877     20.430236      6.998511       0.0         0.0           2.0   \n192878     20.584004      6.998511       0.0         0.0           0.0   \n\n        N_Patent_Reg  N_of_Korean_Patent  STP_Code_1_Weight  \\\n0                0.0                 0.0              100.0   \n1                0.0                 0.0              100.0   \n2                0.0                 0.0              100.0   \n3                0.0                 0.0              100.0   \n4                0.0                 0.0                0.0   \n...              ...                 ...                ...   \n192874           1.0                 3.0               50.0   \n192875           0.0                 0.0              100.0   \n192876           0.0                 0.0               80.0   \n192877           2.0                 4.0              100.0   \n192878           0.0                 0.0               50.0   \n\n        STP_Code_2_Weight  Application_Area_1_Weight  ...  SixT_2  \\\n0                     0.0                      100.0  ...       0   \n1                     0.0                      100.0  ...       0   \n2                     0.0                      100.0  ...       0   \n3                     0.0                      100.0  ...       0   \n4                     0.0                      100.0  ...       0   \n...                   ...                        ...  ...     ...   \n192874               30.0                       50.0  ...       4   \n192875                0.0                      100.0  ...       4   \n192876               20.0                       60.0  ...       9   \n192877                0.0                      100.0  ...       9   \n192878               30.0                       50.0  ...       3   \n\n        Econ_Social  National_Strategy_2  RnD_Stage  Cowork_Cor  Cowork_Uni  \\\n0                 0                    0          0           0           0   \n1                 0                    0          0           0           0   \n2                 0                    0          0           0           0   \n3                 0                    0          0           0           0   \n4                 0                    0          0           0           0   \n...             ...                  ...        ...         ...         ...   \n192874            4                    7          2           0           0   \n192875            5                    0          3           0           0   \n192876            2                    8          3           1           0   \n192877            2                    8          3           1           0   \n192878            2                    3          0           1           1   \n\n        Cowork_Inst  Cowork_Abroad  Cowork_etc  Comm_Success  \n0                 0              0           0           0.0  \n1                 0              0           0           0.0  \n2                 0              0           0           0.0  \n3                 0              0           0           0.0  \n4                 0              0           0           0.0  \n...             ...            ...         ...           ...  \n192874            0              0           0           0.0  \n192875            0              0           1           0.0  \n192876            1              0           0           0.0  \n192877            1              0           0           1.0  \n192878            1              0           0           0.0  \n\n[192879 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Log_RnD_Fund</th>\n      <th>Log_Duration</th>\n      <th>N_of_SCI</th>\n      <th>N_of_Paper</th>\n      <th>N_Patent_App</th>\n      <th>N_Patent_Reg</th>\n      <th>N_of_Korean_Patent</th>\n      <th>STP_Code_1_Weight</th>\n      <th>STP_Code_2_Weight</th>\n      <th>Application_Area_1_Weight</th>\n      <th>...</th>\n      <th>SixT_2</th>\n      <th>Econ_Social</th>\n      <th>National_Strategy_2</th>\n      <th>RnD_Stage</th>\n      <th>Cowork_Cor</th>\n      <th>Cowork_Uni</th>\n      <th>Cowork_Inst</th>\n      <th>Cowork_Abroad</th>\n      <th>Cowork_etc</th>\n      <th>Comm_Success</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19.568083</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.365120</td>\n      <td>5.897157</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>19.673444</td>\n      <td>5.808145</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.504390</td>\n      <td>4.804029</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>192874</th>\n      <td>20.723266</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>30.0</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192875</th>\n      <td>21.920324</td>\n      <td>6.302621</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192876</th>\n      <td>20.482467</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>20.0</td>\n      <td>60.0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>192877</th>\n      <td>20.430236</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>192878</th>\n      <td>20.584004</td>\n      <td>6.998511</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>30.0</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>192879 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#카테고리 컬럼 > 0,1,2,3....변경\n",
    "for i in CATEGORICAL_COLUMN:\n",
    "    value = data[i].unique()\n",
    "    val_list = list(value)\n",
    "    new_val_list = list(range(0, len(val_list)))\n",
    "    data[i]= data[i].replace(val_list,new_val_list)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "x_train  = train_data.drop(LABEL_COLUMN,axis = 1)\n",
    "y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "x_val  = val_data.drop(LABEL_COLUMN,axis = 1)\n",
    "y_val = val_data[LABEL_COLUMN]\n",
    "\n",
    "x_test  = test_data.drop(LABEL_COLUMN,axis = 1)\n",
    "y_test = test_data[LABEL_COLUMN]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:42:22,878]\u001B[0m A new study created in memory with name: no-name-05803b21-7fd5-4bdb-945f-a90a1979c676\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8612369258943102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8612369258943102\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8278936564662766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8278936564662766\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125239\n",
      "[6]\tvalid_0's binary_error: 0.118758\n",
      "[7]\tvalid_0's binary_error: 0.109685\n",
      "[8]\tvalid_0's binary_error: 0.102297\n",
      "[9]\tvalid_0's binary_error: 0.0982794\n",
      "[10]\tvalid_0's binary_error: 0.0953631\n",
      "[11]\tvalid_0's binary_error: 0.0943262\n",
      "[12]\tvalid_0's binary_error: 0.0924468\n",
      "[13]\tvalid_0's binary_error: 0.0914423\n",
      "[14]\tvalid_0's binary_error: 0.0904054\n",
      "[15]\tvalid_0's binary_error: 0.0894333\n",
      "[16]\tvalid_0's binary_error: 0.0884612\n",
      "[17]\tvalid_0's binary_error: 0.0879427\n",
      "[18]\tvalid_0's binary_error: 0.0875539\n",
      "[19]\tvalid_0's binary_error: 0.0867762\n",
      "[20]\tvalid_0's binary_error: 0.0859985\n",
      "[21]\tvalid_0's binary_error: 0.0853828\n",
      "[22]\tvalid_0's binary_error: 0.0850264\n",
      "[23]\tvalid_0's binary_error: 0.0850588\n",
      "[24]\tvalid_0's binary_error: 0.084508\n",
      "[25]\tvalid_0's binary_error: 0.0838599\n",
      "[26]\tvalid_0's binary_error: 0.0836979\n",
      "[27]\tvalid_0's binary_error: 0.0830822\n",
      "[28]\tvalid_0's binary_error: 0.0836007\n",
      "[29]\tvalid_0's binary_error: 0.0836979\n",
      "[30]\tvalid_0's binary_error: 0.0838923\n",
      "[31]\tvalid_0's binary_error: 0.0840543\n",
      "[32]\tvalid_0's binary_error: 0.0835683\n",
      "[33]\tvalid_0's binary_error: 0.0835035\n",
      "[34]\tvalid_0's binary_error: 0.0840219\n",
      "[35]\tvalid_0's binary_error: 0.0837951\n",
      "[36]\tvalid_0's binary_error: 0.0835683\n",
      "[37]\tvalid_0's binary_error: 0.0835359\n",
      "[38]\tvalid_0's binary_error: 0.0838923\n",
      "[39]\tvalid_0's binary_error: 0.0840867\n",
      "[40]\tvalid_0's binary_error: 0.0840867\n",
      "[41]\tvalid_0's binary_error: 0.0837951\n",
      "[42]\tvalid_0's binary_error: 0.0837627\n",
      "[43]\tvalid_0's binary_error: 0.0836007\n",
      "[44]\tvalid_0's binary_error: 0.0839247\n",
      "[45]\tvalid_0's binary_error: 0.0832442\n",
      "[46]\tvalid_0's binary_error: 0.0832118\n",
      "[47]\tvalid_0's binary_error: 0.0835359\n",
      "[48]\tvalid_0's binary_error: 0.0836007\n",
      "[49]\tvalid_0's binary_error: 0.0835683\n",
      "[50]\tvalid_0's binary_error: 0.083471\n",
      "[51]\tvalid_0's binary_error: 0.0834062\n",
      "[52]\tvalid_0's binary_error: 0.0838275\n",
      "[53]\tvalid_0's binary_error: 0.0835035\n",
      "[54]\tvalid_0's binary_error: 0.0840219\n",
      "[55]\tvalid_0's binary_error: 0.0838599\n",
      "[56]\tvalid_0's binary_error: 0.0838599\n",
      "[57]\tvalid_0's binary_error: 0.0842163\n",
      "[58]\tvalid_0's binary_error: 0.0840867\n",
      "[59]\tvalid_0's binary_error: 0.0840219\n",
      "[60]\tvalid_0's binary_error: 0.0837951\n",
      "[61]\tvalid_0's binary_error: 0.0839571\n",
      "[62]\tvalid_0's binary_error: 0.0839247\n",
      "[63]\tvalid_0's binary_error: 0.0838923\n",
      "[64]\tvalid_0's binary_error: 0.0837303\n",
      "[65]\tvalid_0's binary_error: 0.0841191\n",
      "[66]\tvalid_0's binary_error: 0.0841839\n",
      "[67]\tvalid_0's binary_error: 0.0840867\n",
      "[68]\tvalid_0's binary_error: 0.0840867\n",
      "[69]\tvalid_0's binary_error: 0.0841191\n",
      "[70]\tvalid_0's binary_error: 0.0841839\n",
      "[71]\tvalid_0's binary_error: 0.0843783\n",
      "[72]\tvalid_0's binary_error: 0.0841839\n",
      "[73]\tvalid_0's binary_error: 0.0843135\n",
      "[74]\tvalid_0's binary_error: 0.0844431\n",
      "[75]\tvalid_0's binary_error: 0.0843135\n",
      "[76]\tvalid_0's binary_error: 0.0842487\n",
      "[77]\tvalid_0's binary_error: 0.0846052\n",
      "[78]\tvalid_0's binary_error: 0.0847348\n",
      "[79]\tvalid_0's binary_error: 0.0845728\n",
      "[80]\tvalid_0's binary_error: 0.0842811\n",
      "[81]\tvalid_0's binary_error: 0.0844107\n",
      "[82]\tvalid_0's binary_error: 0.0847672\n",
      "[83]\tvalid_0's binary_error: 0.0850912\n",
      "[84]\tvalid_0's binary_error: 0.0847348\n",
      "[85]\tvalid_0's binary_error: 0.0847024\n",
      "[86]\tvalid_0's binary_error: 0.0848644\n",
      "[87]\tvalid_0's binary_error: 0.0847348\n",
      "[88]\tvalid_0's binary_error: 0.0844756\n",
      "[89]\tvalid_0's binary_error: 0.0846376\n",
      "[90]\tvalid_0's binary_error: 0.0845728\n",
      "[91]\tvalid_0's binary_error: 0.0847672\n",
      "[92]\tvalid_0's binary_error: 0.0848968\n",
      "[93]\tvalid_0's binary_error: 0.0848644\n",
      "[94]\tvalid_0's binary_error: 0.0848968\n",
      "[95]\tvalid_0's binary_error: 0.0851236\n",
      "[96]\tvalid_0's binary_error: 0.0855449\n",
      "[97]\tvalid_0's binary_error: 0.0853828\n",
      "[98]\tvalid_0's binary_error: 0.085156\n",
      "[99]\tvalid_0's binary_error: 0.0851884\n",
      "[100]\tvalid_0's binary_error: 0.0853828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:42:52,807]\u001B[0m Trial 0 finished with value: 0.6125359401955146 and parameters: {'num_leaves': 444, 'feature_fraction': 0.8278936564662766, 'bagging_fraction': 0.8612369258943102, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 0 with value: 0.6125359401955146.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.31585867769331194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31585867769331194\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2169533754467558, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2169533754467558\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125466\n",
      "[6]\tvalid_0's binary_error: 0.125433\n",
      "[7]\tvalid_0's binary_error: 0.125045\n",
      "[8]\tvalid_0's binary_error: 0.124915\n",
      "[9]\tvalid_0's binary_error: 0.124688\n",
      "[10]\tvalid_0's binary_error: 0.123327\n",
      "[11]\tvalid_0's binary_error: 0.121189\n",
      "[12]\tvalid_0's binary_error: 0.120767\n",
      "[13]\tvalid_0's binary_error: 0.119504\n",
      "[14]\tvalid_0's binary_error: 0.119504\n",
      "[15]\tvalid_0's binary_error: 0.115907\n",
      "[16]\tvalid_0's binary_error: 0.114027\n",
      "[17]\tvalid_0's binary_error: 0.111176\n",
      "[18]\tvalid_0's binary_error: 0.110301\n",
      "[19]\tvalid_0's binary_error: 0.108\n",
      "[20]\tvalid_0's binary_error: 0.107028\n",
      "[21]\tvalid_0's binary_error: 0.105797\n",
      "[22]\tvalid_0's binary_error: 0.104987\n",
      "[23]\tvalid_0's binary_error: 0.102913\n",
      "[24]\tvalid_0's binary_error: 0.102168\n",
      "[25]\tvalid_0's binary_error: 0.102103\n",
      "[26]\tvalid_0's binary_error: 0.101844\n",
      "[27]\tvalid_0's binary_error: 0.100612\n",
      "[28]\tvalid_0's binary_error: 0.0997699\n",
      "[29]\tvalid_0's binary_error: 0.0977609\n",
      "[30]\tvalid_0's binary_error: 0.0965944\n",
      "[31]\tvalid_0's binary_error: 0.0957519\n",
      "[32]\tvalid_0's binary_error: 0.094715\n",
      "[33]\tvalid_0's binary_error: 0.0936457\n",
      "[34]\tvalid_0's binary_error: 0.0938401\n",
      "[35]\tvalid_0's binary_error: 0.0940345\n",
      "[36]\tvalid_0's binary_error: 0.0932569\n",
      "[37]\tvalid_0's binary_error: 0.0928032\n",
      "[38]\tvalid_0's binary_error: 0.0921876\n",
      "[39]\tvalid_0's binary_error: 0.0917015\n",
      "[40]\tvalid_0's binary_error: 0.0914099\n",
      "[41]\tvalid_0's binary_error: 0.0913451\n",
      "[42]\tvalid_0's binary_error: 0.0906646\n",
      "[43]\tvalid_0's binary_error: 0.090697\n",
      "[44]\tvalid_0's binary_error: 0.0905998\n",
      "[45]\tvalid_0's binary_error: 0.0902109\n",
      "[46]\tvalid_0's binary_error: 0.0901461\n",
      "[47]\tvalid_0's binary_error: 0.0902433\n",
      "[48]\tvalid_0's binary_error: 0.0902433\n",
      "[49]\tvalid_0's binary_error: 0.0900165\n",
      "[50]\tvalid_0's binary_error: 0.0897249\n",
      "[51]\tvalid_0's binary_error: 0.0892712\n",
      "[52]\tvalid_0's binary_error: 0.0892388\n",
      "[53]\tvalid_0's binary_error: 0.0887852\n",
      "[54]\tvalid_0's binary_error: 0.0884612\n",
      "[55]\tvalid_0's binary_error: 0.088526\n",
      "[56]\tvalid_0's binary_error: 0.0884612\n",
      "[57]\tvalid_0's binary_error: 0.0875539\n",
      "[58]\tvalid_0's binary_error: 0.0877483\n",
      "[59]\tvalid_0's binary_error: 0.0871326\n",
      "[60]\tvalid_0's binary_error: 0.0874243\n",
      "[61]\tvalid_0's binary_error: 0.0875863\n",
      "[62]\tvalid_0's binary_error: 0.0876187\n",
      "[63]\tvalid_0's binary_error: 0.0872298\n",
      "[64]\tvalid_0's binary_error: 0.0872622\n",
      "[65]\tvalid_0's binary_error: 0.0869382\n",
      "[66]\tvalid_0's binary_error: 0.086841\n",
      "[67]\tvalid_0's binary_error: 0.0866142\n",
      "[68]\tvalid_0's binary_error: 0.086679\n",
      "[69]\tvalid_0's binary_error: 0.0864846\n",
      "[70]\tvalid_0's binary_error: 0.0862901\n",
      "[71]\tvalid_0's binary_error: 0.0862253\n",
      "[72]\tvalid_0's binary_error: 0.0863225\n",
      "[73]\tvalid_0's binary_error: 0.0862577\n",
      "[74]\tvalid_0's binary_error: 0.0864522\n",
      "[75]\tvalid_0's binary_error: 0.0866142\n",
      "[76]\tvalid_0's binary_error: 0.0866466\n",
      "[77]\tvalid_0's binary_error: 0.0864846\n",
      "[78]\tvalid_0's binary_error: 0.0864846\n",
      "[79]\tvalid_0's binary_error: 0.0864522\n",
      "[80]\tvalid_0's binary_error: 0.0863225\n",
      "[81]\tvalid_0's binary_error: 0.0863549\n",
      "[82]\tvalid_0's binary_error: 0.0861281\n",
      "[83]\tvalid_0's binary_error: 0.0859661\n",
      "[84]\tvalid_0's binary_error: 0.0859013\n",
      "[85]\tvalid_0's binary_error: 0.0858365\n",
      "[86]\tvalid_0's binary_error: 0.0857393\n",
      "[87]\tvalid_0's binary_error: 0.0855773\n",
      "[88]\tvalid_0's binary_error: 0.0855125\n",
      "[89]\tvalid_0's binary_error: 0.0856097\n",
      "[90]\tvalid_0's binary_error: 0.0855449\n",
      "[91]\tvalid_0's binary_error: 0.0855773\n",
      "[92]\tvalid_0's binary_error: 0.0853504\n",
      "[93]\tvalid_0's binary_error: 0.0852532\n",
      "[94]\tvalid_0's binary_error: 0.0853504\n",
      "[95]\tvalid_0's binary_error: 0.0847672\n",
      "[96]\tvalid_0's binary_error: 0.0850264\n",
      "[97]\tvalid_0's binary_error: 0.085318\n",
      "[98]\tvalid_0's binary_error: 0.0851884\n",
      "[99]\tvalid_0's binary_error: 0.0854801\n",
      "[100]\tvalid_0's binary_error: 0.0853504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:43:15,311]\u001B[0m Trial 1 finished with value: 0.5776740758934054 and parameters: {'num_leaves': 407, 'feature_fraction': 0.2169533754467558, 'bagging_fraction': 0.31585867769331194, 'bagging_freq': 0, 'min_child_samples': 25}. Best is trial 0 with value: 0.6125359401955146.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9215722410827153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9215722410827153\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5154910855885831, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5154910855885831\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125336\n",
      "[6]\tvalid_0's binary_error: 0.124623\n",
      "[7]\tvalid_0's binary_error: 0.120638\n",
      "[8]\tvalid_0's binary_error: 0.116814\n",
      "[9]\tvalid_0's binary_error: 0.110657\n",
      "[10]\tvalid_0's binary_error: 0.10463\n",
      "[11]\tvalid_0's binary_error: 0.102103\n",
      "[12]\tvalid_0's binary_error: 0.0988302\n",
      "[13]\tvalid_0's binary_error: 0.0972425\n",
      "[14]\tvalid_0's binary_error: 0.0953631\n",
      "[15]\tvalid_0's binary_error: 0.0932245\n",
      "[16]\tvalid_0's binary_error: 0.0921227\n",
      "[17]\tvalid_0's binary_error: 0.0918635\n",
      "[18]\tvalid_0's binary_error: 0.0910534\n",
      "[19]\tvalid_0's binary_error: 0.0899517\n",
      "[20]\tvalid_0's binary_error: 0.0894333\n",
      "[21]\tvalid_0's binary_error: 0.0886232\n",
      "[22]\tvalid_0's binary_error: 0.0880723\n",
      "[23]\tvalid_0's binary_error: 0.0868086\n",
      "[24]\tvalid_0's binary_error: 0.0865494\n",
      "[25]\tvalid_0's binary_error: 0.0862577\n",
      "[26]\tvalid_0's binary_error: 0.0856097\n",
      "[27]\tvalid_0's binary_error: 0.085156\n",
      "[28]\tvalid_0's binary_error: 0.0851884\n",
      "[29]\tvalid_0's binary_error: 0.0852532\n",
      "[30]\tvalid_0's binary_error: 0.0854152\n",
      "[31]\tvalid_0's binary_error: 0.0852532\n",
      "[32]\tvalid_0's binary_error: 0.0853828\n",
      "[33]\tvalid_0's binary_error: 0.084994\n",
      "[34]\tvalid_0's binary_error: 0.084994\n",
      "[35]\tvalid_0's binary_error: 0.0846376\n",
      "[36]\tvalid_0's binary_error: 0.0846052\n",
      "[37]\tvalid_0's binary_error: 0.0846376\n",
      "[38]\tvalid_0's binary_error: 0.084508\n",
      "[39]\tvalid_0's binary_error: 0.0843459\n",
      "[40]\tvalid_0's binary_error: 0.0843459\n",
      "[41]\tvalid_0's binary_error: 0.0839571\n",
      "[42]\tvalid_0's binary_error: 0.0836655\n",
      "[43]\tvalid_0's binary_error: 0.0835359\n",
      "[44]\tvalid_0's binary_error: 0.0837627\n",
      "[45]\tvalid_0's binary_error: 0.0835359\n",
      "[46]\tvalid_0's binary_error: 0.083309\n",
      "[47]\tvalid_0's binary_error: 0.0835359\n",
      "[48]\tvalid_0's binary_error: 0.0835683\n",
      "[49]\tvalid_0's binary_error: 0.0838923\n",
      "[50]\tvalid_0's binary_error: 0.0835683\n",
      "[51]\tvalid_0's binary_error: 0.0830498\n",
      "[52]\tvalid_0's binary_error: 0.0835359\n",
      "[53]\tvalid_0's binary_error: 0.0834062\n",
      "[54]\tvalid_0's binary_error: 0.0835035\n",
      "[55]\tvalid_0's binary_error: 0.0839571\n",
      "[56]\tvalid_0's binary_error: 0.0837627\n",
      "[57]\tvalid_0's binary_error: 0.0834386\n",
      "[58]\tvalid_0's binary_error: 0.0835359\n",
      "[59]\tvalid_0's binary_error: 0.083309\n",
      "[60]\tvalid_0's binary_error: 0.0828878\n",
      "[61]\tvalid_0's binary_error: 0.0832766\n",
      "[62]\tvalid_0's binary_error: 0.083471\n",
      "[63]\tvalid_0's binary_error: 0.0832118\n",
      "[64]\tvalid_0's binary_error: 0.083147\n",
      "[65]\tvalid_0's binary_error: 0.083309\n",
      "[66]\tvalid_0's binary_error: 0.0833738\n",
      "[67]\tvalid_0's binary_error: 0.0835683\n",
      "[68]\tvalid_0's binary_error: 0.0839571\n",
      "[69]\tvalid_0's binary_error: 0.0833738\n",
      "[70]\tvalid_0's binary_error: 0.0835035\n",
      "[71]\tvalid_0's binary_error: 0.0836655\n",
      "[72]\tvalid_0's binary_error: 0.0835035\n",
      "[73]\tvalid_0's binary_error: 0.0837627\n",
      "[74]\tvalid_0's binary_error: 0.0835035\n",
      "[75]\tvalid_0's binary_error: 0.0833414\n",
      "[76]\tvalid_0's binary_error: 0.0835683\n",
      "[77]\tvalid_0's binary_error: 0.0833414\n",
      "[78]\tvalid_0's binary_error: 0.0834062\n",
      "[79]\tvalid_0's binary_error: 0.0836979\n",
      "[80]\tvalid_0's binary_error: 0.0835359\n",
      "[81]\tvalid_0's binary_error: 0.0840867\n",
      "[82]\tvalid_0's binary_error: 0.0842163\n",
      "[83]\tvalid_0's binary_error: 0.0845404\n",
      "[84]\tvalid_0's binary_error: 0.0842163\n",
      "[85]\tvalid_0's binary_error: 0.0842811\n",
      "[86]\tvalid_0's binary_error: 0.0846376\n",
      "[87]\tvalid_0's binary_error: 0.0845728\n",
      "[88]\tvalid_0's binary_error: 0.0849292\n",
      "[89]\tvalid_0's binary_error: 0.0842811\n",
      "[90]\tvalid_0's binary_error: 0.0849292\n",
      "[91]\tvalid_0's binary_error: 0.084994\n",
      "[92]\tvalid_0's binary_error: 0.0852532\n",
      "[93]\tvalid_0's binary_error: 0.0852532\n",
      "[94]\tvalid_0's binary_error: 0.084994\n",
      "[95]\tvalid_0's binary_error: 0.0850264\n",
      "[96]\tvalid_0's binary_error: 0.084832\n",
      "[97]\tvalid_0's binary_error: 0.0852208\n",
      "[98]\tvalid_0's binary_error: 0.085318\n",
      "[99]\tvalid_0's binary_error: 0.0852208\n",
      "[100]\tvalid_0's binary_error: 0.0850264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:43:45,186]\u001B[0m Trial 2 finished with value: 0.613712567926928 and parameters: {'num_leaves': 456, 'feature_fraction': 0.5154910855885831, 'bagging_fraction': 0.9215722410827153, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 2 with value: 0.613712567926928.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9959174744999726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9959174744999726\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6775020309388302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6775020309388302\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125433\n",
      "[6]\tvalid_0's binary_error: 0.121545\n",
      "[7]\tvalid_0's binary_error: 0.113023\n",
      "[8]\tvalid_0's binary_error: 0.105829\n",
      "[9]\tvalid_0's binary_error: 0.0993163\n",
      "[10]\tvalid_0's binary_error: 0.096238\n",
      "[11]\tvalid_0's binary_error: 0.0953631\n",
      "[12]\tvalid_0's binary_error: 0.0940021\n",
      "[13]\tvalid_0's binary_error: 0.0923172\n",
      "[14]\tvalid_0's binary_error: 0.0906646\n",
      "[15]\tvalid_0's binary_error: 0.0892712\n",
      "[16]\tvalid_0's binary_error: 0.088364\n",
      "[17]\tvalid_0's binary_error: 0.087003\n",
      "[18]\tvalid_0's binary_error: 0.086841\n",
      "[19]\tvalid_0's binary_error: 0.086517\n",
      "[20]\tvalid_0's binary_error: 0.0860309\n",
      "[21]\tvalid_0's binary_error: 0.0850264\n",
      "[22]\tvalid_0's binary_error: 0.0849616\n",
      "[23]\tvalid_0's binary_error: 0.0846376\n",
      "[24]\tvalid_0's binary_error: 0.0842163\n",
      "[25]\tvalid_0's binary_error: 0.0843783\n",
      "[26]\tvalid_0's binary_error: 0.0841191\n",
      "[27]\tvalid_0's binary_error: 0.0835683\n",
      "[28]\tvalid_0's binary_error: 0.0832766\n",
      "[29]\tvalid_0's binary_error: 0.0835035\n",
      "[30]\tvalid_0's binary_error: 0.082985\n",
      "[31]\tvalid_0's binary_error: 0.083147\n",
      "[32]\tvalid_0's binary_error: 0.0832118\n",
      "[33]\tvalid_0's binary_error: 0.0834386\n",
      "[34]\tvalid_0's binary_error: 0.0832766\n",
      "[35]\tvalid_0's binary_error: 0.0832442\n",
      "[36]\tvalid_0's binary_error: 0.0830174\n",
      "[37]\tvalid_0's binary_error: 0.082985\n",
      "[38]\tvalid_0's binary_error: 0.0827906\n",
      "[39]\tvalid_0's binary_error: 0.0826286\n",
      "[40]\tvalid_0's binary_error: 0.0821425\n",
      "[41]\tvalid_0's binary_error: 0.0824341\n",
      "[42]\tvalid_0's binary_error: 0.0820129\n",
      "[43]\tvalid_0's binary_error: 0.0821101\n",
      "[44]\tvalid_0's binary_error: 0.0823045\n",
      "[45]\tvalid_0's binary_error: 0.0821749\n",
      "[46]\tvalid_0's binary_error: 0.0822397\n",
      "[47]\tvalid_0's binary_error: 0.0823693\n",
      "[48]\tvalid_0's binary_error: 0.0824017\n",
      "[49]\tvalid_0's binary_error: 0.0820453\n",
      "[50]\tvalid_0's binary_error: 0.0820129\n",
      "[51]\tvalid_0's binary_error: 0.0823693\n",
      "[52]\tvalid_0's binary_error: 0.0824017\n",
      "[53]\tvalid_0's binary_error: 0.0822721\n",
      "[54]\tvalid_0's binary_error: 0.0819805\n",
      "[55]\tvalid_0's binary_error: 0.0816889\n",
      "[56]\tvalid_0's binary_error: 0.0822397\n",
      "[57]\tvalid_0's binary_error: 0.0824341\n",
      "[58]\tvalid_0's binary_error: 0.0823693\n",
      "[59]\tvalid_0's binary_error: 0.0822397\n",
      "[60]\tvalid_0's binary_error: 0.0819481\n",
      "[61]\tvalid_0's binary_error: 0.0820129\n",
      "[62]\tvalid_0's binary_error: 0.0818185\n",
      "[63]\tvalid_0's binary_error: 0.0818509\n",
      "[64]\tvalid_0's binary_error: 0.0818509\n",
      "[65]\tvalid_0's binary_error: 0.0821425\n",
      "[66]\tvalid_0's binary_error: 0.0821101\n",
      "[67]\tvalid_0's binary_error: 0.0825962\n",
      "[68]\tvalid_0's binary_error: 0.0825962\n",
      "[69]\tvalid_0's binary_error: 0.0827582\n",
      "[70]\tvalid_0's binary_error: 0.0827258\n",
      "[71]\tvalid_0's binary_error: 0.0831146\n",
      "[72]\tvalid_0's binary_error: 0.082985\n",
      "[73]\tvalid_0's binary_error: 0.0827582\n",
      "[74]\tvalid_0's binary_error: 0.0823369\n",
      "[75]\tvalid_0's binary_error: 0.0825962\n",
      "[76]\tvalid_0's binary_error: 0.082661\n",
      "[77]\tvalid_0's binary_error: 0.0827906\n",
      "[78]\tvalid_0's binary_error: 0.0826286\n",
      "[79]\tvalid_0's binary_error: 0.0829202\n",
      "[80]\tvalid_0's binary_error: 0.0829202\n",
      "[81]\tvalid_0's binary_error: 0.0830174\n",
      "[82]\tvalid_0's binary_error: 0.0830822\n",
      "[83]\tvalid_0's binary_error: 0.0829526\n",
      "[84]\tvalid_0's binary_error: 0.0830174\n",
      "[85]\tvalid_0's binary_error: 0.0830498\n",
      "[86]\tvalid_0's binary_error: 0.0830498\n",
      "[87]\tvalid_0's binary_error: 0.083147\n",
      "[88]\tvalid_0's binary_error: 0.0832118\n",
      "[89]\tvalid_0's binary_error: 0.0833738\n",
      "[90]\tvalid_0's binary_error: 0.0832766\n",
      "[91]\tvalid_0's binary_error: 0.0830822\n",
      "[92]\tvalid_0's binary_error: 0.0831794\n",
      "[93]\tvalid_0's binary_error: 0.0831146\n",
      "[94]\tvalid_0's binary_error: 0.0830822\n",
      "[95]\tvalid_0's binary_error: 0.0832442\n",
      "[96]\tvalid_0's binary_error: 0.082985\n",
      "[97]\tvalid_0's binary_error: 0.083147\n",
      "[98]\tvalid_0's binary_error: 0.0834386\n",
      "[99]\tvalid_0's binary_error: 0.0835035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:44:05,833]\u001B[0m Trial 3 finished with value: 0.6104241303594129 and parameters: {'num_leaves': 320, 'feature_fraction': 0.6775020309388302, 'bagging_fraction': 0.9959174744999726, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 2 with value: 0.613712567926928.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_error: 0.0836331\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8523707362384287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8523707362384287\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7836754005155878, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7836754005155878\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125466\n",
      "[6]\tvalid_0's binary_error: 0.121869\n",
      "[7]\tvalid_0's binary_error: 0.113865\n",
      "[8]\tvalid_0's binary_error: 0.103367\n",
      "[9]\tvalid_0's binary_error: 0.0979878\n",
      "[10]\tvalid_0's binary_error: 0.0964972\n",
      "[11]\tvalid_0's binary_error: 0.0954927\n",
      "[12]\tvalid_0's binary_error: 0.0933865\n",
      "[13]\tvalid_0's binary_error: 0.0924144\n",
      "[14]\tvalid_0's binary_error: 0.0914099\n",
      "[15]\tvalid_0's binary_error: 0.0905026\n",
      "[16]\tvalid_0's binary_error: 0.0897573\n",
      "[17]\tvalid_0's binary_error: 0.0891416\n",
      "[18]\tvalid_0's binary_error: 0.0882343\n",
      "[19]\tvalid_0's binary_error: 0.0881695\n",
      "[20]\tvalid_0's binary_error: 0.0879103\n",
      "[21]\tvalid_0's binary_error: 0.087327\n",
      "[22]\tvalid_0's binary_error: 0.0865494\n",
      "[23]\tvalid_0's binary_error: 0.0862253\n",
      "[24]\tvalid_0's binary_error: 0.0860309\n",
      "[25]\tvalid_0's binary_error: 0.085156\n",
      "[26]\tvalid_0's binary_error: 0.0849616\n",
      "[27]\tvalid_0's binary_error: 0.08467\n",
      "[28]\tvalid_0's binary_error: 0.0846376\n",
      "[29]\tvalid_0's binary_error: 0.084508\n",
      "[30]\tvalid_0's binary_error: 0.0842811\n",
      "[31]\tvalid_0's binary_error: 0.0846052\n",
      "[32]\tvalid_0's binary_error: 0.0841515\n",
      "[33]\tvalid_0's binary_error: 0.0838275\n",
      "[34]\tvalid_0's binary_error: 0.0836655\n",
      "[35]\tvalid_0's binary_error: 0.0836007\n",
      "[36]\tvalid_0's binary_error: 0.0836007\n",
      "[37]\tvalid_0's binary_error: 0.0836007\n",
      "[38]\tvalid_0's binary_error: 0.0829202\n",
      "[39]\tvalid_0's binary_error: 0.0829526\n",
      "[40]\tvalid_0's binary_error: 0.0827906\n",
      "[41]\tvalid_0's binary_error: 0.0831146\n",
      "[42]\tvalid_0's binary_error: 0.0827906\n",
      "[43]\tvalid_0's binary_error: 0.0829202\n",
      "[44]\tvalid_0's binary_error: 0.082661\n",
      "[45]\tvalid_0's binary_error: 0.0824665\n",
      "[46]\tvalid_0's binary_error: 0.0822073\n",
      "[47]\tvalid_0's binary_error: 0.0824665\n",
      "[48]\tvalid_0's binary_error: 0.0823693\n",
      "[49]\tvalid_0's binary_error: 0.0826934\n",
      "[50]\tvalid_0's binary_error: 0.0828554\n",
      "[51]\tvalid_0's binary_error: 0.082985\n",
      "[52]\tvalid_0's binary_error: 0.082661\n",
      "[53]\tvalid_0's binary_error: 0.0827582\n",
      "[54]\tvalid_0's binary_error: 0.0827906\n",
      "[55]\tvalid_0's binary_error: 0.0829526\n",
      "[56]\tvalid_0's binary_error: 0.0828878\n",
      "[57]\tvalid_0's binary_error: 0.082985\n",
      "[58]\tvalid_0's binary_error: 0.0830174\n",
      "[59]\tvalid_0's binary_error: 0.082823\n",
      "[60]\tvalid_0's binary_error: 0.0828554\n",
      "[61]\tvalid_0's binary_error: 0.083147\n",
      "[62]\tvalid_0's binary_error: 0.0828554\n",
      "[63]\tvalid_0's binary_error: 0.082985\n",
      "[64]\tvalid_0's binary_error: 0.0831794\n",
      "[65]\tvalid_0's binary_error: 0.0832442\n",
      "[66]\tvalid_0's binary_error: 0.0831794\n",
      "[67]\tvalid_0's binary_error: 0.0830174\n",
      "[68]\tvalid_0's binary_error: 0.0832766\n",
      "[69]\tvalid_0's binary_error: 0.082985\n",
      "[70]\tvalid_0's binary_error: 0.0830498\n",
      "[71]\tvalid_0's binary_error: 0.0832766\n",
      "[72]\tvalid_0's binary_error: 0.082985\n",
      "[73]\tvalid_0's binary_error: 0.0829526\n",
      "[74]\tvalid_0's binary_error: 0.0825638\n",
      "[75]\tvalid_0's binary_error: 0.0828554\n",
      "[76]\tvalid_0's binary_error: 0.0829526\n",
      "[77]\tvalid_0's binary_error: 0.0828878\n",
      "[78]\tvalid_0's binary_error: 0.0829202\n",
      "[79]\tvalid_0's binary_error: 0.082823\n",
      "[80]\tvalid_0's binary_error: 0.082985\n",
      "[81]\tvalid_0's binary_error: 0.0828554\n",
      "[82]\tvalid_0's binary_error: 0.0828554\n",
      "[83]\tvalid_0's binary_error: 0.0830174\n",
      "[84]\tvalid_0's binary_error: 0.0828554\n",
      "[85]\tvalid_0's binary_error: 0.0825962\n",
      "[86]\tvalid_0's binary_error: 0.0827906\n",
      "[87]\tvalid_0's binary_error: 0.0824989\n",
      "[88]\tvalid_0's binary_error: 0.0827258\n",
      "[89]\tvalid_0's binary_error: 0.0827258\n",
      "[90]\tvalid_0's binary_error: 0.0827906\n",
      "[91]\tvalid_0's binary_error: 0.083147\n",
      "[92]\tvalid_0's binary_error: 0.0830822\n",
      "[93]\tvalid_0's binary_error: 0.0830498\n",
      "[94]\tvalid_0's binary_error: 0.0834062\n",
      "[95]\tvalid_0's binary_error: 0.0832118\n",
      "[96]\tvalid_0's binary_error: 0.0832766\n",
      "[97]\tvalid_0's binary_error: 0.0833414\n",
      "[98]\tvalid_0's binary_error: 0.0833414\n",
      "[99]\tvalid_0's binary_error: 0.0837951\n",
      "[100]\tvalid_0's binary_error: 0.0837951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-09-29 16:44:12,967]\u001B[0m Trial 4 finished with value: 0.6025459688826025 and parameters: {'num_leaves': 101, 'feature_fraction': 0.7836754005155878, 'bagging_fraction': 0.8523707362384287, 'bagging_freq': 10, 'min_child_samples': 15}. Best is trial 2 with value: 0.613712567926928.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study.best_params: 0.613712567926928\n",
      "Number of finished trials: 5\n",
      "Best trial: {'num_leaves': 456, 'feature_fraction': 0.5154910855885831, 'bagging_fraction': 0.9215722410827153, 'bagging_freq': 3, 'min_child_samples': 67}\n",
      "study.best_params: {'num_leaves': 456, 'feature_fraction': 0.5154910855885831, 'bagging_fraction': 0.9215722410827153, 'bagging_freq': 3, 'min_child_samples': 67}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_error\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "    }\n",
    "    lgbm = LGBMClassifier(**param)\n",
    "    lgbm.fit(x_train, y_train,  eval_set = (x_val,y_val),\n",
    "             categorical_feature =CATEGORICAL_COLUMN)\n",
    "    pred = lgbm.predict(x_test)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "\n",
    "    return f1\n",
    "\n",
    "studyLGBM = optuna.create_study(direction='maximize')\n",
    "studyLGBM.optimize( objective, n_trials = 5)\n",
    "\n",
    "print('study.best_params:', studyLGBM.best_trial.value)\n",
    "print('Number of finished trials:', len(studyLGBM.trials))\n",
    "print('Best trial:', studyLGBM.best_trial.params)\n",
    "print('study.best_params:', studyLGBM.best_params)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'objective': 'binary',\n 'metric': 'binary_error',\n 'verbosity': -1,\n 'boosting_type': 'gbdt',\n 'num_leaves': 456,\n 'feature_fraction': 0.5154910855885831,\n 'bagging_fraction': 0.9215722410827153,\n 'bagging_freq': 3,\n 'min_child_samples': 67}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter = studyLGBM.best_params\n",
    "parameter_2 ={\"objective\": \"binary\",\n",
    "        \"metric\": \"binary_error\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "\t\t\t  }\n",
    "parameter =dict(**parameter_2, **parameter)\n",
    "parameter\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9215722410827153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9215722410827153\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5154910855885831, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5154910855885831\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[1]\tvalid_0's binary_error: 0.125466\n",
      "[2]\tvalid_0's binary_error: 0.125466\n",
      "[3]\tvalid_0's binary_error: 0.125466\n",
      "[4]\tvalid_0's binary_error: 0.125466\n",
      "[5]\tvalid_0's binary_error: 0.125336\n",
      "[6]\tvalid_0's binary_error: 0.124623\n",
      "[7]\tvalid_0's binary_error: 0.120638\n",
      "[8]\tvalid_0's binary_error: 0.116814\n",
      "[9]\tvalid_0's binary_error: 0.110657\n",
      "[10]\tvalid_0's binary_error: 0.10463\n",
      "[11]\tvalid_0's binary_error: 0.102103\n",
      "[12]\tvalid_0's binary_error: 0.0988302\n",
      "[13]\tvalid_0's binary_error: 0.0972425\n",
      "[14]\tvalid_0's binary_error: 0.0953631\n",
      "[15]\tvalid_0's binary_error: 0.0932245\n",
      "[16]\tvalid_0's binary_error: 0.0921227\n",
      "[17]\tvalid_0's binary_error: 0.0918635\n",
      "[18]\tvalid_0's binary_error: 0.0910534\n",
      "[19]\tvalid_0's binary_error: 0.0899517\n",
      "[20]\tvalid_0's binary_error: 0.0894333\n",
      "[21]\tvalid_0's binary_error: 0.0886232\n",
      "[22]\tvalid_0's binary_error: 0.0880723\n",
      "[23]\tvalid_0's binary_error: 0.0868086\n",
      "[24]\tvalid_0's binary_error: 0.0865494\n",
      "[25]\tvalid_0's binary_error: 0.0862577\n",
      "[26]\tvalid_0's binary_error: 0.0856097\n",
      "[27]\tvalid_0's binary_error: 0.085156\n",
      "[28]\tvalid_0's binary_error: 0.0851884\n",
      "[29]\tvalid_0's binary_error: 0.0852532\n",
      "[30]\tvalid_0's binary_error: 0.0854152\n",
      "[31]\tvalid_0's binary_error: 0.0852532\n",
      "[32]\tvalid_0's binary_error: 0.0853828\n",
      "[33]\tvalid_0's binary_error: 0.084994\n",
      "[34]\tvalid_0's binary_error: 0.084994\n",
      "[35]\tvalid_0's binary_error: 0.0846376\n",
      "[36]\tvalid_0's binary_error: 0.0846052\n",
      "[37]\tvalid_0's binary_error: 0.0846376\n",
      "[38]\tvalid_0's binary_error: 0.084508\n",
      "[39]\tvalid_0's binary_error: 0.0843459\n",
      "[40]\tvalid_0's binary_error: 0.0843459\n",
      "[41]\tvalid_0's binary_error: 0.0839571\n",
      "[42]\tvalid_0's binary_error: 0.0836655\n",
      "[43]\tvalid_0's binary_error: 0.0835359\n",
      "[44]\tvalid_0's binary_error: 0.0837627\n",
      "[45]\tvalid_0's binary_error: 0.0835359\n",
      "[46]\tvalid_0's binary_error: 0.083309\n",
      "[47]\tvalid_0's binary_error: 0.0835359\n",
      "[48]\tvalid_0's binary_error: 0.0835683\n",
      "[49]\tvalid_0's binary_error: 0.0838923\n",
      "[50]\tvalid_0's binary_error: 0.0835683\n",
      "[51]\tvalid_0's binary_error: 0.0830498\n",
      "[52]\tvalid_0's binary_error: 0.0835359\n",
      "[53]\tvalid_0's binary_error: 0.0834062\n",
      "[54]\tvalid_0's binary_error: 0.0835035\n",
      "[55]\tvalid_0's binary_error: 0.0839571\n",
      "[56]\tvalid_0's binary_error: 0.0837627\n",
      "[57]\tvalid_0's binary_error: 0.0834386\n",
      "[58]\tvalid_0's binary_error: 0.0835359\n",
      "[59]\tvalid_0's binary_error: 0.083309\n",
      "[60]\tvalid_0's binary_error: 0.0828878\n",
      "[61]\tvalid_0's binary_error: 0.0832766\n",
      "[62]\tvalid_0's binary_error: 0.083471\n",
      "[63]\tvalid_0's binary_error: 0.0832118\n",
      "[64]\tvalid_0's binary_error: 0.083147\n",
      "[65]\tvalid_0's binary_error: 0.083309\n",
      "[66]\tvalid_0's binary_error: 0.0833738\n",
      "[67]\tvalid_0's binary_error: 0.0835683\n",
      "[68]\tvalid_0's binary_error: 0.0839571\n",
      "[69]\tvalid_0's binary_error: 0.0833738\n",
      "[70]\tvalid_0's binary_error: 0.0835035\n",
      "[71]\tvalid_0's binary_error: 0.0836655\n",
      "[72]\tvalid_0's binary_error: 0.0835035\n",
      "[73]\tvalid_0's binary_error: 0.0837627\n",
      "[74]\tvalid_0's binary_error: 0.0835035\n",
      "[75]\tvalid_0's binary_error: 0.0833414\n",
      "[76]\tvalid_0's binary_error: 0.0835683\n",
      "[77]\tvalid_0's binary_error: 0.0833414\n",
      "[78]\tvalid_0's binary_error: 0.0834062\n",
      "[79]\tvalid_0's binary_error: 0.0836979\n",
      "[80]\tvalid_0's binary_error: 0.0835359\n",
      "[81]\tvalid_0's binary_error: 0.0840867\n",
      "[82]\tvalid_0's binary_error: 0.0842163\n",
      "[83]\tvalid_0's binary_error: 0.0845404\n",
      "[84]\tvalid_0's binary_error: 0.0842163\n",
      "[85]\tvalid_0's binary_error: 0.0842811\n",
      "[86]\tvalid_0's binary_error: 0.0846376\n",
      "[87]\tvalid_0's binary_error: 0.0845728\n",
      "[88]\tvalid_0's binary_error: 0.0849292\n",
      "[89]\tvalid_0's binary_error: 0.0842811\n",
      "[90]\tvalid_0's binary_error: 0.0849292\n",
      "[91]\tvalid_0's binary_error: 0.084994\n",
      "[92]\tvalid_0's binary_error: 0.0852532\n",
      "[93]\tvalid_0's binary_error: 0.0852532\n",
      "[94]\tvalid_0's binary_error: 0.084994\n",
      "[95]\tvalid_0's binary_error: 0.0850264\n",
      "[96]\tvalid_0's binary_error: 0.084832\n",
      "[97]\tvalid_0's binary_error: 0.0852208\n",
      "[98]\tvalid_0's binary_error: 0.085318\n",
      "[99]\tvalid_0's binary_error: 0.0852208\n",
      "[100]\tvalid_0's binary_error: 0.0850264\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMClassifier(bagging_fraction=0.9215722410827153, bagging_freq=3,\n               feature_fraction=0.5154910855885831, metric='binary_error',\n               min_child_samples=67, num_leaves=456, objective='binary',\n               verbosity=-1)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.9215722410827153, bagging_freq=3,\n               feature_fraction=0.5154910855885831, metric=&#x27;binary_error&#x27;,\n               min_child_samples=67, num_leaves=456, objective=&#x27;binary&#x27;,\n               verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.9215722410827153, bagging_freq=3,\n               feature_fraction=0.5154910855885831, metric=&#x27;binary_error&#x27;,\n               min_child_samples=67, num_leaves=456, objective=&#x27;binary&#x27;,\n               verbosity=-1)</pre></div></div></div></div></div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(**parameter)\n",
    "lgbm.fit(x_train, y_train,  eval_set = (x_val,y_val),\n",
    "         categorical_feature =CATEGORICAL_COLUMN)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[32581  1120]\n",
      " [ 2221  2654]]\n",
      "accuracy:0.9134, precision:0.7032, recall:0.5444, f1-score:0.6137\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm.predict(x_test)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion)\n",
    "    print('accuracy:{}, precision:{}, recall:{}, f1-score:{}'.format(round(accuracy,4), round(precision,4) ,round(recall,4), round(f1,4)))\n",
    "\n",
    "get_clf_eval(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}